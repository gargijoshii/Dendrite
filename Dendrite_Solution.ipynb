{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFi1BZ-dgy5v",
        "outputId": "d076bf27-13c3-4b22-d917-0cd4d22db236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading striprtf-0.0.27-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.27\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install striprtf scikit-learn pandas xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Importing Required Libraries**"
      ],
      "metadata": {
        "id": "crAAgN4WoufU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from striprtf.striprtf import rtf_to_text\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, f_classif\n",
        "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier, RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "B41U6Pdnotji"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The import statements bring in various libraries used throughout the script:\n",
        "\n",
        "- **striprtf.striprtf**: To convert RTF content into plain text.  \n",
        "- **json, pandas**: For handling JSON data and manipulating dataframes.  \n",
        "- **Scikit-learn**: For various machine learning tasks like regression, classification, feature selection, model evaluation, etc.  \n",
        "- **xgboost**: A library for the XGBoost model, used for both classification and regression tasks.  \n",
        "- **google.colab.files**: To upload files directly in a Google Colab environment.\n"
      ],
      "metadata": {
        "id": "_7Ck8c9op5dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Upload the JSON Configuration File**"
      ],
      "metadata": {
        "id": "pDWIoZz7qTjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Please upload the JSON configuration file (RTF format):\")\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Re_VX8-kp49E",
        "outputId": "f349c231-f127-4831-d5b1-55178ac4e2e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the JSON configuration file (RTF format):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a8ee1ff-e2c0-4c31-adaa-9e326ac5c7b9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a8ee1ff-e2c0-4c31-adaa-9e326ac5c7b9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving algoparams_from_ui.json.rtf to algoparams_from_ui.json.rtf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The user is prompted to upload a configuration file in RTF format, which contains important data for parsing the target and features."
      ],
      "metadata": {
        "id": "3ghOdVyRqeSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Reading and Parsing the JSON Configuration**"
      ],
      "metadata": {
        "id": "JZquWtNUqzb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, 'r') as rtf_file:\n",
        "    rtf_content = rtf_file.read()\n",
        "\n",
        "plain_text = rtf_to_text(rtf_content)\n",
        "try:\n",
        "    json_start = plain_text.find(\"{\")\n",
        "    json_data = plain_text[json_start:]\n",
        "    parsed_data = json.loads(json_data)\n",
        "    print(\"Parsed JSON Data:\")\n",
        "    print(json.dumps(parsed_data, indent=4))\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"Error decoding JSON:\", e)\n",
        "    exit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8cmJCVDqcFb",
        "outputId": "58c4e447-5e44-4096-8106-9e39269cdaa1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed JSON Data:\n",
            "{\n",
            "    \"session_name\": \"test\",\n",
            "    \"session_description\": \"test\",\n",
            "    \"design_state_data\": {\n",
            "        \"session_info\": {\n",
            "            \"project_id\": \"1\",\n",
            "            \"experiment_id\": \"kkkk-11\",\n",
            "            \"dataset\": \"iris_modified.csv\",\n",
            "            \"session_name\": \"test\",\n",
            "            \"session_description\": \"test\"\n",
            "        },\n",
            "        \"target\": {\n",
            "            \"prediction_type\": \"Regression\",\n",
            "            \"target\": \"petal_width\",\n",
            "            \"type\": \"regression\",\n",
            "            \"partitioning\": true\n",
            "        },\n",
            "        \"train\": {\n",
            "            \"policy\": \"Split the dataset\",\n",
            "            \"time_variable\": \"sepal_length\",\n",
            "            \"sampling_method\": \"No sampling(whole data)\",\n",
            "            \"split\": \"Randomly\",\n",
            "            \"k_fold\": false,\n",
            "            \"train_ratio\": 0,\n",
            "            \"random_seed\": 0\n",
            "        },\n",
            "        \"metrics\": {\n",
            "            \"optomize_model_hyperparameters_for\": \"AUC\",\n",
            "            \"optimize_threshold_for\": \"F1 Score\",\n",
            "            \"compute_lift_at\": 0,\n",
            "            \"cost_matrix_gain_for_true_prediction_true_result\": 1,\n",
            "            \"cost_matrix_gain_for_true_prediction_false_result\": 0,\n",
            "            \"cost_matrix_gain_for_false_prediction_true_result\": 0,\n",
            "            \"cost_matrix_gain_for_false_prediction_false_result\": 0\n",
            "        },\n",
            "        \"feature_handling\": {\n",
            "            \"sepal_length\": {\n",
            "                \"feature_name\": \"sepal_length\",\n",
            "                \"is_selected\": true,\n",
            "                \"feature_variable_type\": \"numerical\",\n",
            "                \"feature_details\": {\n",
            "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "                    \"rescaling\": \"No rescaling\",\n",
            "                    \"make_derived_feats\": false,\n",
            "                    \"missing_values\": \"Impute\",\n",
            "                    \"impute_with\": \"Average of values\",\n",
            "                    \"impute_value\": 0\n",
            "                }\n",
            "            },\n",
            "            \"sepal_width\": {\n",
            "                \"feature_name\": \"sepal_width\",\n",
            "                \"is_selected\": true,\n",
            "                \"feature_variable_type\": \"numerical\",\n",
            "                \"feature_details\": {\n",
            "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "                    \"rescaling\": \"No rescaling\",\n",
            "                    \"make_derived_feats\": false,\n",
            "                    \"missing_values\": \"Impute\",\n",
            "                    \"impute_with\": \"custom\",\n",
            "                    \"impute_value\": -1\n",
            "                }\n",
            "            },\n",
            "            \"petal_length\": {\n",
            "                \"feature_name\": \"petal_length\",\n",
            "                \"is_selected\": true,\n",
            "                \"feature_variable_type\": \"numerical\",\n",
            "                \"feature_details\": {\n",
            "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "                    \"rescaling\": \"No rescaling\",\n",
            "                    \"make_derived_feats\": false,\n",
            "                    \"missing_values\": \"Impute\",\n",
            "                    \"impute_with\": \"Average of values\",\n",
            "                    \"impute_value\": 0\n",
            "                }\n",
            "            },\n",
            "            \"petal_width\": {\n",
            "                \"feature_name\": \"petal_width\",\n",
            "                \"is_selected\": true,\n",
            "                \"feature_variable_type\": \"numerical\",\n",
            "                \"feature_details\": {\n",
            "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "                    \"rescaling\": \"No rescaling\",\n",
            "                    \"make_derived_feats\": false,\n",
            "                    \"missing_values\": \"Impute\",\n",
            "                    \"impute_with\": \"custom\",\n",
            "                    \"impute_value\": -2\n",
            "                }\n",
            "            },\n",
            "            \"species\": {\n",
            "                \"feature_name\": \"species\",\n",
            "                \"is_selected\": true,\n",
            "                \"feature_variable_type\": \"text\",\n",
            "                \"feature_details\": {\n",
            "                    \"text_handling\": \"Tokenize and hash\",\n",
            "                    \"hash_columns\": 0\n",
            "                }\n",
            "            }\n",
            "        },\n",
            "        \"feature_generation\": {\n",
            "            \"linear_interactions\": [\n",
            "                [\n",
            "                    \"petal_length\",\n",
            "                    \"sepal_width\"\n",
            "                ]\n",
            "            ],\n",
            "            \"linear_scalar_type\": \"robust\",\n",
            "            \"polynomial_interactions\": [\n",
            "                \"petal_length/sepal_width\",\n",
            "                \"petal_width/species\"\n",
            "            ],\n",
            "            \"explicit_pairwise_interactions\": [\n",
            "                \"sepal_width/sepal_length\",\n",
            "                \"petal_width/sepal_length\"\n",
            "            ]\n",
            "        },\n",
            "        \"feature_reduction\": {\n",
            "            \"feature_reduction_method\": \"Tree-based\",\n",
            "            \"num_of_features_to_keep\": \"4\",\n",
            "            \"num_of_trees\": \"5\",\n",
            "            \"depth_of_trees\": \"6\"\n",
            "        },\n",
            "        \"hyperparameters\": {\n",
            "            \"stratergy\": \"Grid Search\",\n",
            "            \"shuffle_grid\": true,\n",
            "            \"random_state\": 1,\n",
            "            \"max_iterations\": 2,\n",
            "            \"max_search_time\": 3,\n",
            "            \"parallelism\": 5,\n",
            "            \"cross_validation_stratergy\": \"Time-based K-fold(with overlap)\",\n",
            "            \"num_of_folds\": 6,\n",
            "            \"split_ratio\": 0,\n",
            "            \"stratified\": true\n",
            "        },\n",
            "        \"weighting_stratergy\": {\n",
            "            \"weighting_stratergy_method\": \"Sample weights\",\n",
            "            \"weighting_stratergy_weight_variable\": \"petal_length\"\n",
            "        },\n",
            "        \"probability_calibration\": {\n",
            "            \"probability_calibration_method\": \"Sigmoid - Platt Scaling\"\n",
            "        },\n",
            "        \"algorithms\": {\n",
            "            \"RandomForestClassifier\": {\n",
            "                \"model_name\": \"Random Forest Classifier\",\n",
            "                \"is_selected\": false,\n",
            "                \"min_trees\": 10,\n",
            "                \"max_trees\": 30,\n",
            "                \"feature_sampling_statergy\": \"Default\",\n",
            "                \"min_depth\": 20,\n",
            "                \"max_depth\": 30,\n",
            "                \"min_samples_per_leaf_min_value\": 5,\n",
            "                \"min_samples_per_leaf_max_value\": 50,\n",
            "                \"parallelism\": 0\n",
            "            },\n",
            "            \"RandomForestRegressor\": {\n",
            "                \"model_name\": \"Random Forest Regressor\",\n",
            "                \"is_selected\": true,\n",
            "                \"min_trees\": 10,\n",
            "                \"max_trees\": 20,\n",
            "                \"feature_sampling_statergy\": \"Default\",\n",
            "                \"min_depth\": 20,\n",
            "                \"max_depth\": 25,\n",
            "                \"min_samples_per_leaf_min_value\": 5,\n",
            "                \"min_samples_per_leaf_max_value\": 10,\n",
            "                \"parallelism\": 0\n",
            "            },\n",
            "            \"GBTClassifier\": {\n",
            "                \"model_name\": \"Gradient Boosted Trees\",\n",
            "                \"is_selected\": false,\n",
            "                \"num_of_BoostingStages\": [\n",
            "                    67,\n",
            "                    89\n",
            "                ],\n",
            "                \"feature_sampling_statergy\": \"Fixed number\",\n",
            "                \"learningRate\": [],\n",
            "                \"use_deviance\": true,\n",
            "                \"use_exponential\": false,\n",
            "                \"fixed_number\": 22,\n",
            "                \"min_subsample\": 1,\n",
            "                \"max_subsample\": 2,\n",
            "                \"min_stepsize\": 0.1,\n",
            "                \"max_stepsize\": 0.5,\n",
            "                \"min_iter\": 20,\n",
            "                \"max_iter\": 40,\n",
            "                \"min_depth\": 5,\n",
            "                \"max_depth\": 7\n",
            "            },\n",
            "            \"GBTRegressor\": {\n",
            "                \"model_name\": \"Gradient Boosted Trees\",\n",
            "                \"is_selected\": false,\n",
            "                \"num_of_BoostingStages\": [\n",
            "                    67,\n",
            "                    89\n",
            "                ],\n",
            "                \"feature_sampling_statergy\": \"Fixed number\",\n",
            "                \"use_deviance\": true,\n",
            "                \"use_exponential\": false,\n",
            "                \"fixed_number\": 22,\n",
            "                \"min_subsample\": 1,\n",
            "                \"max_subsample\": 2,\n",
            "                \"min_stepsize\": 0.1,\n",
            "                \"max_stepsize\": 0.5,\n",
            "                \"min_iter\": 20,\n",
            "                \"max_iter\": 40,\n",
            "                \"min_depth\": 5,\n",
            "                \"max_depth\": 7\n",
            "            },\n",
            "            \"LinearRegression\": {\n",
            "                \"model_name\": \"LinearRegression\",\n",
            "                \"is_selected\": false,\n",
            "                \"parallelism\": 2,\n",
            "                \"min_iter\": 30,\n",
            "                \"max_iter\": 50,\n",
            "                \"min_regparam\": 0.5,\n",
            "                \"max_regparam\": 0.8,\n",
            "                \"min_elasticnet\": 0.5,\n",
            "                \"max_elasticnet\": 0.8\n",
            "            },\n",
            "            \"LogisticRegression\": {\n",
            "                \"model_name\": \"LogisticRegression\",\n",
            "                \"is_selected\": false,\n",
            "                \"parallelism\": 2,\n",
            "                \"min_iter\": 30,\n",
            "                \"max_iter\": 50,\n",
            "                \"min_regparam\": 0.5,\n",
            "                \"max_regparam\": 0.8,\n",
            "                \"min_elasticnet\": 0.5,\n",
            "                \"max_elasticnet\": 0.8\n",
            "            },\n",
            "            \"RidgeRegression\": {\n",
            "                \"model_name\": \"RidgeRegression\",\n",
            "                \"is_selected\": false,\n",
            "                \"regularization_term\": \"Specify values to test\",\n",
            "                \"min_iter\": 30,\n",
            "                \"max_iter\": 50,\n",
            "                \"min_regparam\": 0.5,\n",
            "                \"max_regparam\": 0.8\n",
            "            },\n",
            "            \"LassoRegression\": {\n",
            "                \"model_name\": \"Lasso Regression\",\n",
            "                \"is_selected\": false,\n",
            "                \"regularization_term\": \"Specify values to test\",\n",
            "                \"min_iter\": 30,\n",
            "                \"max_iter\": 50,\n",
            "                \"min_regparam\": 0.5,\n",
            "                \"max_regparam\": 0.8\n",
            "            },\n",
            "            \"ElasticNetRegression\": {\n",
            "                \"model_name\": \"Lasso Regression\",\n",
            "                \"is_selected\": false,\n",
            "                \"regularization_term\": \"Specify values to test\",\n",
            "                \"min_iter\": 30,\n",
            "                \"max_iter\": 50,\n",
            "                \"min_regparam\": 0.5,\n",
            "                \"max_regparam\": 0.8,\n",
            "                \"min_elasticnet\": 0.5,\n",
            "                \"max_elasticnet\": 0.8\n",
            "            },\n",
            "            \"xg_boost\": {\n",
            "                \"model_name\": \"XG Boost\",\n",
            "                \"is_selected\": false,\n",
            "                \"use_gradient_boosted_tree\": true,\n",
            "                \"dart\": true,\n",
            "                \"tree_method\": \"\",\n",
            "                \"random_state\": 0,\n",
            "                \"max_num_of_trees\": 0,\n",
            "                \"early_stopping\": true,\n",
            "                \"early_stopping_rounds\": 2,\n",
            "                \"max_depth_of_tree\": [\n",
            "                    56,\n",
            "                    89\n",
            "                ],\n",
            "                \"learningRate\": [\n",
            "                    89,\n",
            "                    76\n",
            "                ],\n",
            "                \"l1_regularization\": [\n",
            "                    77\n",
            "                ],\n",
            "                \"l2_regularization\": [\n",
            "                    78\n",
            "                ],\n",
            "                \"gamma\": [\n",
            "                    68\n",
            "                ],\n",
            "                \"min_child_weight\": [\n",
            "                    67\n",
            "                ],\n",
            "                \"sub_sample\": [\n",
            "                    67\n",
            "                ],\n",
            "                \"col_sample_by_tree\": [\n",
            "                    67\n",
            "                ],\n",
            "                \"replace_missing_values\": false,\n",
            "                \"parallelism\": 0\n",
            "            },\n",
            "            \"DecisionTreeRegressor\": {\n",
            "                \"model_name\": \"Decision Tree\",\n",
            "                \"is_selected\": false,\n",
            "                \"min_depth\": 4,\n",
            "                \"max_depth\": 7,\n",
            "                \"use_gini\": false,\n",
            "                \"use_entropy\": true,\n",
            "                \"min_samples_per_leaf\": [\n",
            "                    12,\n",
            "                    6\n",
            "                ],\n",
            "                \"use_best\": true,\n",
            "                \"use_random\": true\n",
            "            },\n",
            "            \"DecisionTreeClassifier\": {\n",
            "                \"model_name\": \"Decision Tree\",\n",
            "                \"is_selected\": false,\n",
            "                \"min_depth\": 4,\n",
            "                \"max_depth\": 7,\n",
            "                \"use_gini\": false,\n",
            "                \"use_entropy\": true,\n",
            "                \"min_samples_per_leaf\": [\n",
            "                    12,\n",
            "                    6\n",
            "                ],\n",
            "                \"use_best\": true,\n",
            "                \"use_random\": true\n",
            "            },\n",
            "            \"SVM\": {\n",
            "                \"model_name\": \"Support Vector Machine\",\n",
            "                \"is_selected\": false,\n",
            "                \"linear_kernel\": true,\n",
            "                \"rep_kernel\": true,\n",
            "                \"polynomial_kernel\": true,\n",
            "                \"sigmoid_kernel\": true,\n",
            "                \"c_value\": [\n",
            "                    566,\n",
            "                    79\n",
            "                ],\n",
            "                \"auto\": true,\n",
            "                \"scale\": true,\n",
            "                \"custom_gamma_values\": true,\n",
            "                \"tolerance\": 7,\n",
            "                \"max_iterations\": 7\n",
            "            },\n",
            "            \"SGD\": {\n",
            "                \"model_name\": \"Stochastic Gradient Descent\",\n",
            "                \"is_selected\": false,\n",
            "                \"use_logistics\": true,\n",
            "                \"use_modified_hubber_loss\": false,\n",
            "                \"max_iterations\": false,\n",
            "                \"tolerance\": 56,\n",
            "                \"use_l1_regularization\": \"on\",\n",
            "                \"use_l2_regularization\": \"on\",\n",
            "                \"use_elastic_net_regularization\": true,\n",
            "                \"alpha_value\": [\n",
            "                    79,\n",
            "                    56\n",
            "                ],\n",
            "                \"parallelism\": 1\n",
            "            },\n",
            "            \"KNN\": {\n",
            "                \"model_name\": \"KNN\",\n",
            "                \"is_selected\": false,\n",
            "                \"k_value\": [\n",
            "                    78\n",
            "                ],\n",
            "                \"distance_weighting\": true,\n",
            "                \"neighbour_finding_algorithm\": \"Automatic\",\n",
            "                \"random_state\": 0,\n",
            "                \"p_value\": 0\n",
            "            },\n",
            "            \"extra_random_trees\": {\n",
            "                \"model_name\": \"Extra Random Trees\",\n",
            "                \"is_selected\": false,\n",
            "                \"num_of_trees\": [\n",
            "                    45,\n",
            "                    489\n",
            "                ],\n",
            "                \"feature_sampling_statergy\": \"Square root and Logarithm\",\n",
            "                \"max_depth\": [\n",
            "                    12,\n",
            "                    45\n",
            "                ],\n",
            "                \"min_samples_per_leaf\": [\n",
            "                    78,\n",
            "                    56\n",
            "                ],\n",
            "                \"parallelism\": 3\n",
            "            },\n",
            "            \"neural_network\": {\n",
            "                \"model_name\": \"Neural Network\",\n",
            "                \"is_selected\": false,\n",
            "                \"hidden_layer_sizes\": [\n",
            "                    67,\n",
            "                    89\n",
            "                ],\n",
            "                \"activation\": \"\",\n",
            "                \"alpha_value\": 0,\n",
            "                \"max_iterations\": 0,\n",
            "                \"convergence_tolerance\": 0,\n",
            "                \"early_stopping\": true,\n",
            "                \"solver\": \"ADAM\",\n",
            "                \"shuffle_data\": true,\n",
            "                \"initial_learning_rate\": 0,\n",
            "                \"automatic_batching\": true,\n",
            "                \"beta_1\": 0,\n",
            "                \"beta_2\": 0,\n",
            "                \"epsilon\": 0,\n",
            "                \"power_t\": 0,\n",
            "                \"momentum\": 0,\n",
            "                \"use_nesterov_momentum\": false\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **RTF File Reading**:  \n",
        "  The uploaded RTF file is read, and the `rtf_to_text` function is used to convert the RTF file content into plain text.\n",
        "\n",
        "- **JSON Parsing**:  \n",
        "  The JSON content is extracted from the plain text and parsed using Python's `json` library.\n",
        "\n",
        "- **Validation**:  \n",
        "  The script then prints the parsed JSON data to ensure that the correct structure has been extracted.\n"
      ],
      "metadata": {
        "id": "3NEqlFUCq8pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Upload the CSV Dataset**"
      ],
      "metadata": {
        "id": "KQADk_cjrLW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPlease upload the CSV file containing the dataset:\")\n",
        "uploaded_csv = files.upload()\n",
        "csv_file_name = list(uploaded_csv.keys())[0]\n",
        "df = pd.read_csv(csv_file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "CcmSmdKBq74w",
        "outputId": "63ebd622-1968-4d90-924c-1cb10a42dd48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please upload the CSV file containing the dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2df6074-0aec-47bf-93f6-9817be14dd1b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c2df6074-0aec-47bf-93f6-9817be14dd1b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving iris.csv to iris.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **File Upload**:  \n",
        "  The user is asked to upload a CSV file containing the dataset.\n",
        "\n",
        "- **Reading the File**:  \n",
        "  The file is read using `pandas` (`pd.read_csv()`), and it is stored as a dataframe (`df`).\n"
      ],
      "metadata": {
        "id": "PJlcyKGLrVm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Handle Categorical Features**"
      ],
      "metadata": {
        "id": "R8-06nQyrpt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Get target column and features\n",
        "target = parsed_data['design_state_data']['target']['target']\n",
        "features = parsed_data['design_state_data']['feature_handling']\n",
        "\n",
        "# Handle categorical features\n",
        "for feature, details in features.items():\n",
        "    if details['is_selected'] and details['feature_variable_type'] == \"text\":\n",
        "        print(f\"Encoding categorical feature: {feature}\")\n",
        "        le = LabelEncoder()\n",
        "        df[feature] = le.fit_transform(df[feature].astype(str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEMoNNhlrU6e",
        "outputId": "42edc48a-6a43-4996-b58b-b164efcf1198"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding categorical feature: species\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **Label Encoding**:  \n",
        "  The categorical features are encoded using `LabelEncoder`.\n",
        "\n",
        "- **Conversion to Numeric**:  \n",
        "  If a feature is selected and has a type of text, it is converted into numeric values, enabling the models to process it.\n"
      ],
      "metadata": {
        "id": "6eghp_RmsMdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Format the Target Column**"
      ],
      "metadata": {
        "id": "LKBPiwKyse3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_type = input(\"Enter task type (classification/regression): \").strip().lower()\n",
        "if task_type == \"classification\":\n",
        "    if df[target].dtype in [\"float64\", \"int64\"] and df[target].nunique() > 20:\n",
        "        print(f\"Warning: Converting numeric target with {df[target].nunique()} unique values into discrete bins.\")\n",
        "        df[target] = pd.cut(df[target], bins=3, labels=[\"class_1\", \"class_2\", \"class_3\"])\n",
        "    df[target] = df[target].astype(\"category\").cat.codes\n",
        "elif task_type == \"regression\":\n",
        "    df[target] = pd.to_numeric(df[target], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[target])\n",
        "else:\n",
        "    print(\"Invalid task type. Exiting.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AJAdOqbsiC8",
        "outputId": "25421288-c4d1-4cb0-9d1c-60cf9d89b921"
      },
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter task type (classification/regression): regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the task type (classification or regression), the target column is formatted:\n",
        "- **Classification**:  \n",
        "  If the target column is numeric with more than 20 unique values, it is converted into discrete bins (3 classes).\n",
        "\n",
        "- **Regression**:  \n",
        "  The target column is converted to numeric values, and rows with missing target values are dropped.\n"
      ],
      "metadata": {
        "id": "B8mSPsS0ssn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Feature Reduction**"
      ],
      "metadata": {
        "id": "3eS7yIGMtBTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: User selects feature reduction method\n",
        "print(\"\\nFeature Reduction Methods:\")\n",
        "print(\"1. No Reduction\")\n",
        "print(\"2. PCA\")\n",
        "print(\"3. Correlation with Target\")\n",
        "print(\"4. Tree-based Selection\")\n",
        "reduction_choice = input(\"Select a feature reduction method (enter 1, 2, 3, or 4): \").strip()\n",
        "\n",
        "reduced_features = None\n",
        "selected_columns = None  # Track selected feature names or PCA components\n",
        "if reduction_choice == \"1\":\n",
        "    print(\"No Reduction selected. Using all original features.\")\n",
        "    reduced_features = df.drop(columns=[target])\n",
        "    selected_columns = reduced_features.columns.tolist()\n",
        "elif reduction_choice == \"2\":\n",
        "    num_of_features_to_keep = int(input(\"Enter the number of components to keep for PCA: \"))\n",
        "    pca = PCA(n_components=num_of_features_to_keep)\n",
        "    reduced_features = pd.DataFrame(pca.fit_transform(df.drop(columns=[target])),\n",
        "                                    columns=[f\"PC{i+1}\" for i in range(num_of_features_to_keep)])\n",
        "    selected_columns = reduced_features.columns.tolist()\n",
        "elif reduction_choice == \"3\":\n",
        "    num_of_features_to_keep = int(input(\"Enter the number of features to select based on correlation with the target: \"))\n",
        "    score_func = f_regression if task_type == \"regression\" else f_classif\n",
        "    selector = SelectKBest(score_func=score_func, k=num_of_features_to_keep)\n",
        "    reduced_features = selector.fit_transform(df.drop(columns=[target]), df[target])\n",
        "    selected_columns = df.drop(columns=[target]).columns[selector.get_support()].tolist()\n",
        "    reduced_features = pd.DataFrame(reduced_features, columns=selected_columns)\n",
        "elif reduction_choice == \"4\":\n",
        "    num_of_features_to_keep = int(input(\"Enter the number of features to select using Tree-based importance: \"))\n",
        "    tree_model = ExtraTreesRegressor() if task_type == \"regression\" else ExtraTreesClassifier()\n",
        "    tree_model.fit(df.drop(columns=[target]), df[target])\n",
        "    top_features = df.drop(columns=[target]).columns[tree_model.feature_importances_.argsort()[-num_of_features_to_keep:]]\n",
        "    reduced_features = df[top_features]\n",
        "    selected_columns = top_features.tolist()\n",
        "else:\n",
        "    print(\"Invalid choice. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "# Step 6b: Display the selected features or PCA components and their values\n",
        "if selected_columns:\n",
        "    print(\"\\nSelected Features or Components:\")\n",
        "    print(reduced_features.head())\n",
        "else:\n",
        "    print(\"Feature reduction failed or no features selected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6qou7yXxhOi",
        "outputId": "7c775d0b-d737-4f8a-b3c6-f09925a24bc3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Reduction Methods:\n",
            "1. No Reduction\n",
            "2. PCA\n",
            "3. Correlation with Target\n",
            "4. Tree-based Selection\n",
            "Select a feature reduction method (enter 1, 2, 3, or 4): 2\n",
            "Enter the number of components to keep for PCA: 3\n",
            "\n",
            "Selected Features or Components:\n",
            "        PC1       PC2       PC3\n",
            "0 -2.685814  0.305194  0.051476\n",
            "1 -2.715303 -0.178050 -0.172252\n",
            "2 -2.888472 -0.161684  0.048363\n",
            "3 -2.745779 -0.323027  0.026984\n",
            "4 -2.729896  0.307330  0.160715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The user is prompted to select a feature reduction method from the following options:\n",
        "\n",
        "- **PCA (Principal Component Analysis)**:  \n",
        "  Reduces the feature space to a specified number of components.\n",
        "\n",
        "- **Correlation with Target**:  \n",
        "  Selects the most correlated features with the target.\n",
        "\n",
        "- **Tree-based Selection**:  \n",
        "  Uses a tree-based model (e.g., RandomForest, ExtraTrees) to select the most important features.\n",
        "\n",
        "- **No Reduction**:  \n",
        "  No feature reduction; all features are used.\n"
      ],
      "metadata": {
        "id": "0oFjdyx8tscc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Split the Data**"
      ],
      "metadata": {
        "id": "lhnNbwXgt1pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(reduced_features, df[target], test_size=0.2, random_state=42,\n",
        "                                                    stratify=df[target] if task_type == \"classification\" else None)"
      ],
      "metadata": {
        "id": "R0rbYIjdtOtx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **Train-Test Split**:  \n",
        "  The dataset is split into training and testing sets, with **80% for training** and **20% for testing**.\n",
        "\n",
        "- **Stratification**:  \n",
        "  For classification tasks, stratification is used to maintain the distribution of the target classes in both sets.\n"
      ],
      "metadata": {
        "id": "dnnco0lluCr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Model Training and Evaluation**\n",
        "\n"
      ],
      "metadata": {
        "id": "R3gPJ6CEuMTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define available models based on task type\n",
        "if task_type == \"classification\":\n",
        "    available_models = {\n",
        "        \"RandomForestClassifier\": {\"model\": RandomForestClassifier(), \"param_grid\": {'n_estimators': [10, 20], 'max_depth': [5, 10]}},\n",
        "        \"GradientBoostingClassifier\": {\"model\": GradientBoostingClassifier(), \"param_grid\": {'n_estimators': [50], 'max_depth': [3]}},\n",
        "        \"LogisticRegression\": {\"model\": LogisticRegression(), \"param_grid\": {'C': [0.1, 1]}},\n",
        "        \"DecisionTreeClassifier\": {\"model\": DecisionTreeClassifier(), \"param_grid\": {'max_depth': [3, 5, 10]}},\n",
        "        \"SVC\": {\"model\": SVC(), \"param_grid\": {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}},\n",
        "        \"KNeighborsClassifier\": {\"model\": KNeighborsClassifier(), \"param_grid\": {'n_neighbors': [3, 5, 7]}},\n",
        "        \"SGDClassifier\": {\"model\": SGDClassifier(), \"param_grid\": {'alpha': [0.0001, 0.001], 'penalty': ['l2', 'l1']}},\n",
        "        \"MLPClassifier\": {\"model\": MLPClassifier(max_iter=1000), \"param_grid\": {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['relu', 'tanh']}},\n",
        "        \"XGBoostClassifier\": {\"model\": xgboost.XGBClassifier(), \"param_grid\": {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}}\n",
        "    }\n",
        "elif task_type == \"regression\":\n",
        "    available_models = {\n",
        "        \"RandomForestRegressor\": {\"model\": RandomForestRegressor(), \"param_grid\": {'n_estimators': [10, 20], 'max_depth': [5, 10]}},\n",
        "        \"GradientBoostingRegressor\": {\"model\": GradientBoostingRegressor(), \"param_grid\": {'n_estimators': [50], 'max_depth': [3]}},\n",
        "        \"LinearRegression\": {\"model\": LinearRegression(), \"param_grid\": None},\n",
        "        \"Ridge\": {\"model\": Ridge(), \"param_grid\": {'alpha': [0.1, 1.0, 10.0]}},\n",
        "        \"Lasso\": {\"model\": Lasso(), \"param_grid\": {'alpha': [0.1, 1.0, 10.0]}},\n",
        "        \"ElasticNet\": {\"model\": ElasticNet(), \"param_grid\": {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.1, 0.5]}},\n",
        "        \"DecisionTreeRegressor\": {\"model\": DecisionTreeRegressor(), \"param_grid\": {'max_depth': [3, 5, 10]}},\n",
        "        \"SVR\": {\"model\": SVR(), \"param_grid\": {'C': [0.1, 1], 'kernel': ['linear', 'rbf']}},\n",
        "        \"KNeighborsRegressor\": {\"model\": KNeighborsRegressor(), \"param_grid\": {'n_neighbors': [3, 5, 7]}},\n",
        "        \"SGDRegressor\": {\"model\": SGDRegressor(), \"param_grid\": {'alpha': [0.0001, 0.001]}},\n",
        "        \"MLPRegressor\": {\"model\": MLPRegressor(max_iter=1000), \"param_grid\": {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['relu', 'tanh']}},\n",
        "        \"XGBoostRegressor\": {\"model\": xgboost.XGBRegressor(), \"param_grid\": {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}}\n",
        "    }\n",
        "else:\n",
        "    print(\"Invalid task type. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nAvailable Models to Train:\")\n",
        "for model_name in available_models:\n",
        "    print(f\"- {model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iXJV4NyuLxT",
        "outputId": "51d7de0e-6649-4a96-90d0-0b55a5d554b8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Available Models to Train:\n",
            "- RandomForestRegressor\n",
            "- GradientBoostingRegressor\n",
            "- LinearRegression\n",
            "- Ridge\n",
            "- Lasso\n",
            "- ElasticNet\n",
            "- DecisionTreeRegressor\n",
            "- SVR\n",
            "- KNeighborsRegressor\n",
            "- SGDRegressor\n",
            "- MLPRegressor\n",
            "- XGBoostRegressor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Availability:** Based on the task type (classification or regression), a dictionary of available models is defined. Each model has associated hyperparameters that can be tuned using GridSearchCV."
      ],
      "metadata": {
        "id": "-1j4auv5ujtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Model Selection**"
      ],
      "metadata": {
        "id": "1bQapL1WuoFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_models_input = input(\"\\nEnter the model names you want to train (comma-separated): \").strip()\n",
        "selected_models = [model.strip() for model in selected_models_input.split(\",\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUxQeOeNu1hE",
        "outputId": "c4c81266-9e73-4427-d5fe-0bdebe442f51"
      },
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter the model names you want to train (comma-separated): RandomForestRegressor, GradientBoostingRegressor, LinearRegression, Ridge, Lasso, ElasticNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **User Input**:  \n",
        "  The user is asked to input the models they want to train (comma-separated).\n",
        "\n",
        "- **Model Processing**:  \n",
        "  The input is processed to select the specified models from the available list.\n"
      ],
      "metadata": {
        "id": "eQmKY1akusWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Train and Evaluate Models**"
      ],
      "metadata": {
        "id": "Hn_yHdr1vJyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in selected_models:\n",
        "    if model_name not in available_models:\n",
        "        print(f\"Model {model_name} is not available. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nTraining model: {model_name}\")\n",
        "    model_info = available_models[model_name]\n",
        "    model = model_info[\"model\"]\n",
        "    param_grid = model_info[\"param_grid\"]\n",
        "\n",
        "    try:\n",
        "        # Grid search for hyperparameter tuning if param_grid exists\n",
        "        if param_grid:\n",
        "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5,\n",
        "                                       scoring='accuracy' if task_type == \"classification\" else 'neg_mean_squared_error', error_score='raise')\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            best_model = grid_search.best_estimator_\n",
        "            print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            best_model = model\n",
        "\n",
        "        # Evaluate the model\n",
        "        y_pred = best_model.predict(X_test)\n",
        "\n",
        "        if task_type == \"classification\":\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "            print(f\"Accuracy for {model_name}: {accuracy}\")\n",
        "            print(f\"F1 Score for {model_name}: {f1}\")\n",
        "        elif task_type == \"regression\":\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            print(f\"Mean Squared Error for {model_name}: {mse}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {model_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2PaB2RovUnt",
        "outputId": "c6d36f02-3533-4b01-f7be-4ade15a00f5d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model: RandomForestRegressor\n",
            "Best parameters for RandomForestRegressor: {'max_depth': 10, 'n_estimators': 10}\n",
            "Mean Squared Error for RandomForestRegressor: 0.02233333333333333\n",
            "\n",
            "Training model: GradientBoostingRegressor\n",
            "Best parameters for GradientBoostingRegressor: {'max_depth': 3, 'n_estimators': 50}\n",
            "Mean Squared Error for GradientBoostingRegressor: 0.006915289514699861\n",
            "\n",
            "Training model: LinearRegression\n",
            "Mean Squared Error for LinearRegression: 0.018604841823369984\n",
            "\n",
            "Training model: Ridge\n",
            "Best parameters for Ridge: {'alpha': 0.1}\n",
            "Mean Squared Error for Ridge: 0.018724832050328665\n",
            "\n",
            "Training model: Lasso\n",
            "Best parameters for Lasso: {'alpha': 0.1}\n",
            "Mean Squared Error for Lasso: 0.05729888615591594\n",
            "\n",
            "Training model: ElasticNet\n",
            "Best parameters for ElasticNet: {'alpha': 0.1, 'l1_ratio': 0.1}\n",
            "Mean Squared Error for ElasticNet: 0.035678364543306126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Hyperparameter Tuning**:  \n",
        "  For each selected model, `GridSearchCV` is used to tune the hyperparameters.\n",
        "\n",
        "- **Model Training**:  \n",
        "  The model is trained on the training dataset.\n",
        "\n",
        "- **Performance Evaluation**:  \n",
        "  - **Classification**: Evaluated using metrics like **Accuracy** and **F1 Score**.  \n",
        "  - **Regression**: Evaluated using **Mean Squared Error (MSE)**.\n"
      ],
      "metadata": {
        "id": "3wbQUDMuvL91"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}